{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1OCoUeo3SSFidOmgBCP4mfcZzmTe1oFA4",
      "authorship_tag": "ABX9TyNhK1XU0b4zu9BFtuNSWRIv",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/monjjjjj/orchid_classification/blob/main/orchid_classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "RnT0c1rxTfH1"
      },
      "outputs": [],
      "source": [
        "from tensorflow.python import keras\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2 \n",
        "from tensorflow import keras\n",
        "from google.colab import drive\n",
        "from google.colab.patches import cv2_imshow\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras import Sequential\n",
        "from keras import initializers, optimizers\n",
        "from keras.layers import Dense, Flatten, Activation, Dropout, Conv2D, MaxPooling2D, BatchNormalization\n",
        "from keras.applications.resnet import ResNet50\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.utils import np_utils"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# google drive mounted\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BmhKEp0OZqNU",
        "outputId": "80c24511-d26f-488e-915b-75e7ce2c15f4"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# read data\n",
        "labels = []\n",
        "images = []\n",
        "paths = []\n",
        "\n",
        "train_dir = \"/content/drive/MyDrive/orchid_classification/training/\"\n",
        "label_dir = \"/content/drive/MyDrive/orchid_classification/label/label.csv\"\n",
        "\n",
        "#BATCH_SIZE = 32\n",
        "#IMG_SIZE = (224, 224)\n",
        "\n",
        "#train_dataset = image_dataset_from_directory(train_dir, shuffle=True, batch_size=BATCH_SIZE, image_size=IMG_SIZE)\n",
        "\n"
      ],
      "metadata": {
        "id": "rw-qgCOEZ22M"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "for num in range(len(df)):\n",
        "    paths.append(os.path.join('train_dir', df['filename'][:len(df)][num]))\n",
        "    labels.append(df['category'][:len(df)][num])\n",
        "\n",
        "#print(len(paths))\n",
        "#print(paths[0:5])\n",
        "'''"
      ],
      "metadata": {
        "id": "LzcdaFvLkL8K",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "68f2e72c-61e8-4804-f87e-246bfaa435c4"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\nfor num in range(len(df)):\\n    paths.append(os.path.join('train_dir', df['filename'][:len(df)][num]))\\n    labels.append(df['category'][:len(df)][num])\\n\\n#print(len(paths))\\n#print(paths[0:5])\\n\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#read data\n",
        "def load_data():\n",
        "  x_train = []\n",
        "  y_train = []\n",
        "  df = pd.read_csv(label_dir, index_col = \"filename\")\n",
        "  for p in os.listdir(train_dir):\n",
        "    if p != \"label.csv\":\n",
        "      path = train_dir + p\n",
        "      image = cv2.imread(path)\n",
        "      image = image.astype(\"float\") / 255.0\n",
        "      image = cv2.resize(image, (224,224), interpolation = cv2.INTER_AREA)\n",
        "      x_train.append(np.array(image))\n",
        "      y_train.append(df.loc[str(p),\"category\"])\n",
        "  return x_train,y_train\n",
        "\n"
      ],
      "metadata": {
        "id": "vnWhe1PnQFkM"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train, y_train = load_data()\n",
        "\n",
        "# one-hot encoding\n",
        "x_train = np.array(x_train)\n",
        "num_classes = 219\n",
        "y_train = np_utils.to_categorical(y_train, num_classes, dtype = 'float32')"
      ],
      "metadata": {
        "id": "weNI7FkX8n78"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# debug\n",
        "#print(x_train[1:5])\n",
        "#print(y_train[1:5])\n",
        "#print(x_train.shape)\n",
        "#print(y_train.shape)"
      ],
      "metadata": {
        "id": "yARZ5qzsdv4E",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "90965c16-d8af-4b3f-c563-5764998f7095"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(2190, 224, 224, 3)\n",
            "(2190, 219)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# autotune\n",
        "'''\n",
        "AUTOTUNE = tf.data.AUTOTUNE\n",
        "train_dataset = train_dataset.prefetch(buffer_size=AUTOTUNE)\n",
        "'''"
      ],
      "metadata": {
        "id": "O9GhAEGS2Rt0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "d0abd338-232f-4e2e-d650-6bdcc99d288e"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nAUTOTUNE = tf.data.AUTOTUNE\\ntrain_dataset = train_dataset.prefetch(buffer_size=AUTOTUNE)\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# check all the files are images\n",
        "'''\n",
        "def start(Path):\n",
        "    filelist = os.listdir(Path)\n",
        "    for file in filelist:\n",
        "        print(file)\n",
        "        img = Image.open(Path+ file).convert('RGB')\n",
        "    #     # print(img)\n",
        "        img.save(Path + file)\n",
        "    print('Done!')\n",
        "if __name__ == '__main__':\n",
        "    start('/content/drive/MyDrive/orchid_classification/training/')\n",
        "'''"
      ],
      "metadata": {
        "id": "9uqaRW7WNPpR",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "48e3d7ca-a5d8-4166-9b03-77f0b8ffe5c6"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\ndef start(Path):\\n    filelist = os.listdir(Path)\\n    for file in filelist:\\n        print(file)\\n        img = Image.open(Path+ file).convert('RGB')\\n    #     # print(img)\\n        img.save(Path + file)\\n    print('Done!')\\nif __name__ == '__main__':\\n    start('/content/drive/MyDrive/orchid_classification/training/')\\n\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# read data\n",
        "'''\n",
        "def read_image(paths):\n",
        "  for path in paths:\n",
        "    image = cv2.imread(path, cv2.COLOR_GRAY2BGR)\n",
        "    image = image.astype(\"float\") / 255.0\n",
        "    image = cv2.resize(image,(224,224))\n",
        "    images.append(image)\n",
        "\n",
        "read_image('/content/drive/MyDrive/orchid_classification/training/')\n",
        "images = np.asarray(images)\n",
        "images = images.reshape((-1, 224, 224, 3))\n",
        "labels = to_categorical(labels, 219)\n",
        "print(1, labels)\n",
        "'''"
      ],
      "metadata": {
        "id": "5lIy3cRi5eF6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "8617c1f9-2674-4c50-93de-ace7aa0f7ffb"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\ndef read_image(paths):\\n  for path in paths:\\n    image = cv2.imread(path, cv2.COLOR_GRAY2BGR)\\n    image = image.astype(\"float\") / 255.0\\n    image = cv2.resize(image,(224,224))\\n    images.append(image)\\n\\nread_image(\\'/content/drive/MyDrive/orchid_classification/training/\\')\\nimages = np.asarray(images)\\nimages = images.reshape((-1, 224, 224, 3))\\nlabels = to_categorical(labels, 219)\\nprint(1, labels)\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "# data augmentation\n",
        "data_augmentation = tf.keras.Sequential([\n",
        "  tf.keras.layers.experimental.preprocessing.RandomFlip('horizontal'),\n",
        "  tf.keras.layers.experimental.preprocessing.RandomRotation(0.2),\n",
        "])\n",
        "'''"
      ],
      "metadata": {
        "id": "rImh8Bih2Y4t",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "518e4809-ac8d-4a01-9271-6e2e701cc5be"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\n# data augmentation\\ndata_augmentation = tf.keras.Sequential([\\n  tf.keras.layers.experimental.preprocessing.RandomFlip('horizontal'),\\n  tf.keras.layers.experimental.preprocessing.RandomRotation(0.2),\\n])\\n\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "#data augmentation\n",
        "datagen = ImageDataGenerator(\n",
        "        featurewise_center=False,  # set input mean to 0 over the dataset\n",
        "        samplewise_center=False,  # set each sample mean to 0\n",
        "        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
        "        samplewise_std_normalization=False,  # divide each input by its std\n",
        "        zca_whitening=False,  # apply ZCA whitening\n",
        "        rotation_range = 30,  # randomly rotate images in the range (degrees, 0 to 180)\n",
        "        zoom_range = 0.2, # Randomly zoom image \n",
        "        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n",
        "        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n",
        "        horizontal_flip = True,  # randomly flip images\n",
        "        vertical_flip=False)  # randomly flip images\n",
        "\n",
        "\n",
        "datagen.fit(x_train)\n",
        "'''"
      ],
      "metadata": {
        "id": "l3uD7ixtF-Fl",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        },
        "outputId": "7cacb7df-4ff7-4458-fbb3-b98340a409c0"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n#data augmentation\\ndatagen = ImageDataGenerator(\\n        featurewise_center=False,  # set input mean to 0 over the dataset\\n        samplewise_center=False,  # set each sample mean to 0\\n        featurewise_std_normalization=False,  # divide inputs by std of the dataset\\n        samplewise_std_normalization=False,  # divide each input by its std\\n        zca_whitening=False,  # apply ZCA whitening\\n        rotation_range = 30,  # randomly rotate images in the range (degrees, 0 to 180)\\n        zoom_range = 0.2, # Randomly zoom image \\n        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\\n        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\\n        horizontal_flip = True,  # randomly flip images\\n        vertical_flip=False)  # randomly flip images\\n\\n\\ndatagen.fit(x_train)\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# build model\n",
        "def build_model():\n",
        "  model = Sequential()\n",
        "  model.add(ResNet50(include_top=False, weights='imagenet', input_tensor=None, pooling='avg', classes=219, input_shape=(224, 224, 3)))\n",
        "  model.add(Flatten())\n",
        "  model.add(Dense(219,activation='softmax'))\n",
        "\n",
        "  model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "  print(model.summary())\n",
        "  keras.utils.plot_model(model, show_shapes=True, dpi=64, to_file='model2.png')\n",
        "\n",
        "  return model"
      ],
      "metadata": {
        "id": "zu1iCGMMgxrY"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#training\n",
        "model = build_model()\n",
        "\n",
        "train_history = model.fit(x=x_train, y=y_train, batch_size=32, epochs=20, verbose=1)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a3Nfqw8CmolJ",
        "outputId": "60ef463d-206a-48ba-e7f4-1ad4be1041ca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " resnet50 (Functional)       (None, 2048)              23587712  \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 2048)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 219)               448731    \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 24,036,443\n",
            "Trainable params: 23,983,323\n",
            "Non-trainable params: 53,120\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/20\n",
            "21/69 [========>.....................] - ETA: 17:48 - loss: 5.7232 - accuracy: 0.0223"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_history.history.keys())"
      ],
      "metadata": {
        "id": "l6c7FkfP_UBo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def show_train_history(train_history,train,validation):\n",
        "  \n",
        "  if train == 'accuracy':\n",
        "    plt.plot(train_history.history[train])\n",
        "    plt.plot(train_history.history[validation])\n",
        "    plt.title('Model Accuracy')\n",
        "    plt.ylabel('accuracy')\n",
        "    plt.xlabel('epoch')\n",
        "  else:\n",
        "    plt.plot(train_history.history[train])\n",
        "    plt.plot(train_history.history[validation])\n",
        "    plt.title('Model Loss')\n",
        "    plt.ylabel('loss')\n",
        "    plt.xlabel('epoch')\n",
        "\n",
        "  plt.legend(['train','validation'],loc='upper left')\n",
        "  plt.show()\n",
        "\n",
        "show_train_history(train_history,'accuracy','val_accuracy')\n",
        "show_train_history(train_history,'loss','val_loss')"
      ],
      "metadata": {
        "id": "P-BAuDou_Xfg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# summarize history for accuracy\n",
        "plt.plot(train_history.history['accuracy'])\n",
        "plt.plot(train_history.history['val_accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'validation'], loc='upper left') \n",
        "plt.show()"
      ],
      "metadata": {
        "id": "C00pPISM_ayG"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}